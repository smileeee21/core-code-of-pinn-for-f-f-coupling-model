{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12228f1f-777a-4fa0-a0a1-7fc657c455b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My tf.version: 2.10.0,yours:2.10.0\n",
      "Epoch 50 loss: 3.3231567293071556 Elapsed time: 19.38024616241455 seconds\n",
      "Epoch 100 loss: 1.0384451630742886 Elapsed time: 18.046133518218994 seconds\n",
      "Epoch 150 loss: 0.64134916498830918 Elapsed time: 20.71315026283264 seconds\n",
      "Epoch 200 loss: 0.39333314340295106 Elapsed time: 19.621237754821777 seconds\n",
      "Epoch 250 loss: 0.27696565617098573 Elapsed time: 16.888567447662354 seconds\n",
      "Epoch 300 loss: 0.21464777517335337 Elapsed time: 20.21916937828064 seconds\n",
      "Epoch 350 loss: 0.17001193790217514 Elapsed time: 20.92950963973999 seconds\n",
      "Epoch 400 loss: 0.14013079779490853 Elapsed time: 20.440690755844116 seconds\n",
      "Epoch 450 loss: 0.11405048704786303 Elapsed time: 19.748474597930908 seconds\n",
      "Epoch 500 loss: 0.09473734897363445 Elapsed time: 19.942697763442993 seconds\n",
      "MSE for u11: tf.Tensor(0.0004418399033944875, shape=(), dtype=float64)\n",
      "MSE for u12: tf.Tensor(0.0008703366952090529, shape=(), dtype=float64)\n",
      "MSE for p1: tf.Tensor(0.006344494652084735, shape=(), dtype=float64)\n",
      "MSE for u21: tf.Tensor(0.002165825158917032, shape=(), dtype=float64)\n",
      "MSE for u22: tf.Tensor(0.0015115536404633333, shape=(), dtype=float64)\n",
      "MSE for p2: tf.Tensor(0.014140172015505, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "from sympy import symbols, cos, pi, sin, exp, lambdify\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import time\n",
    "np.random.seed(114)\n",
    "tf.random.set_seed(514)\n",
    "print(f\"My tf.version: 2.10.0,yours:{tf.__version__}\")\n",
    "x = symbols('x')\n",
    "y = symbols('y')\n",
    "t = symbols('t')\n",
    "e = exp(1)\n",
    "\n",
    "u11 = x*x*((x-1)**2)*(1-y)*e**(0-t)\n",
    "u12 = x*y*(6*x+y-3*x*y+2*x*x*y-4*x*x-2)*e**(0-t)\n",
    "p1 = cos(pi*x)*sin(pi*y)*e**(0-t)\n",
    "u21 = x*x*(x-1)**2*(1-y)*e**(0-t)\n",
    "u22 = x*y*(6*x+y-3*x*y+2*x*x*y-4*x*x-2)*e**(0-t)\n",
    "p2 = cos(pi*x)*sin(pi*y)*e**(0-t)\n",
    "\n",
    "u11 = lambdify((x, y, t), u11,'tensorflow')\n",
    "u12 = lambdify((x, y, t), u12,'tensorflow')\n",
    "u21 = lambdify((x, y, t), u21,'tensorflow')\n",
    "u22 = lambdify((x, y, t), u22,'tensorflow')\n",
    "p1 = lambdify((x, y, t), p1,'tensorflow')\n",
    "p2 = lambdify((x, y, t), p2,'tensorflow')\n",
    "class NullOptimizer(tf.keras.optimizers.Optimizer):\n",
    "    def __init__(self, name='NullOptimizer', **kwargs):\n",
    "        super(NullOptimizer, self).__init__(name, **kwargs)\n",
    "\n",
    "    def _resource_apply_dense(self, grad, var):\n",
    "        # 不执行任何操作，直接返回梯度和变量\n",
    "        return tf.no_op()\n",
    "\n",
    "    def _resource_apply_sparse(self, grad, var, indices):\n",
    "        # 不执行任何操作，直接返回梯度和变量\n",
    "        return tf.no_op()\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(NullOptimizer, self).get_config()\n",
    "        return config\n",
    "optimizerfake = NullOptimizer()\n",
    "class OnePinn (keras.Sequential):\n",
    "    def __init__(self, Layers, name=None):\n",
    "        super(OnePinn, self).__init__(name=name)\n",
    "        self.add(keras.Input(shape=(Layers[0],), dtype=tf.float64))\n",
    "        for i in range(1, len(Layers) - 1):\n",
    "            self.add(keras.layers.Dense(Layers[i], dtype=tf.float64, activation='tanh'))\n",
    "        self.add(keras.layers.Dense(Layers[-1], dtype=tf.float64, activation=None, name=\"outputs\"))\n",
    "        self.optimizer = tf.keras.optimizers.Adam()\n",
    "    @tf.function\n",
    "    def u_t (self,inputs):\n",
    "        x, y, t = inputs[:, 0:1], inputs[:, 1:2], inputs[:, 2:3]\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            tape.watch(t)\n",
    "            X = tf.stack([x[:,0], y[:,0], t[:,0]], axis=1)\n",
    "            u = self(X)\n",
    "        U_t = tape.gradient(u, t)\n",
    "        del tape\n",
    "        return U_t\n",
    "    @tf.function\n",
    "    def u_x (self,inputs):\n",
    "        x, y, t = inputs[:, 0:1], inputs[:, 1:2], inputs[:, 2:3]\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            tape.watch(x)\n",
    "            X = tf.stack([x[:,0], y[:,0], t[:,0]], axis=1)\n",
    "            u = self(X)\n",
    "        U_x = tape.gradient(u, x)\n",
    "        del tape\n",
    "        return U_x\n",
    "    @tf.function\n",
    "    def u_xx (self,inputs):\n",
    "        x, y, t = inputs[:, 0:1], inputs[:, 1:2], inputs[:, 2:3]\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            tape.watch(x)\n",
    "            X = tf.stack([x[:,0], y[:,0], t[:,0]], axis=1)\n",
    "            u = self(X)\n",
    "            U_x = tape.gradient(u, x)\n",
    "        U_xx=tape.gradient(U_x, x)\n",
    "        del tape\n",
    "        return U_xx\n",
    "    @tf.function\n",
    "    def u_xy (self,inputs):\n",
    "        x, y, t = inputs[:, 0:1], inputs[:, 1:2], inputs[:, 2:3]\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            tape.watch([x,y])\n",
    "            X = tf.stack([x[:,0], y[:,0], t[:,0]], axis=1)\n",
    "            u = self(X)\n",
    "            U_x = tape.gradient(u, x)\n",
    "        U_xy=tape.gradient(U_x, y)\n",
    "        del tape\n",
    "        return U_xy\n",
    "    @tf.function\n",
    "    def u_yy (self,inputs):\n",
    "        x, y, t = inputs[:, 0:1], inputs[:, 1:2], inputs[:, 2:3]\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            tape.watch(y)\n",
    "            X = tf.stack([x[:,0], y[:,0], t[:,0]], axis=1)\n",
    "            u = self(X)\n",
    "            U_y = tape.gradient(u, y)\n",
    "        U_yy=tape.gradient(U_y, y)\n",
    "        del tape\n",
    "        return U_yy\n",
    "    @tf.function\n",
    "    def u_y (self,inputs):\n",
    "        x, y, t = inputs[:, 0:1], inputs[:, 1:2], inputs[:, 2:3]\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            tape.watch(y)\n",
    "            X = tf.stack([x[:,0], y[:,0], t[:,0]], axis=1)\n",
    "            u = self(X)\n",
    "        U_t = tape.gradient(u, y)\n",
    "        del tape\n",
    "        return U_t\n",
    "    @tf.function\n",
    "    def loss_u (self,X_train,u_label):\n",
    "          x, y, t = X_train[:, 0:1], X_train[:, 1:2], X_train[:, 2:3]\n",
    "          up=self(X_train)\n",
    "          loss_U = tf.reduce_mean(tf.square(u_label - up))\n",
    "          return loss_U\n",
    "class UltPinn(keras.Model):\n",
    "    def __init__(self,model_u11,model_u12,model_u21,model_u22,model_p1,model_p2,name=None):\n",
    "          super(UltPinn,self).__init__(name=name)\n",
    "          self.m11 = model_u11 \n",
    "          self.m12 = model_u12\n",
    "          self.m21 = model_u21 \n",
    "          self.m22 = model_u22\n",
    "          self.m1 = model_p1 \n",
    "          self.m2 = model_p2\n",
    "          self.optimizer = tf.keras.optimizers.Adam()\n",
    "          self.optimizer_alpha = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "          self.optimizer_fake=optimizerfake\n",
    "          self.init_weights()\n",
    "    def set_optimizer(self, lun):\n",
    "        if lun % 50 == 0:\n",
    "            self.current_optimizer = self.optimizer_fake\n",
    "        else:\n",
    "            self.current_optimizer = self.optimizer_alpha\n",
    "    def init_weights(self):\n",
    "        self.weights11 = tf.Variable(1.0, trainable=True, dtype=tf.float64)\n",
    "        self.weights12 = tf.Variable(1.0, trainable=True, dtype=tf.float64)\n",
    "        self.weights21= tf.Variable(1.0, trainable=True, dtype=tf.float64)\n",
    "        self.weights22= tf.Variable(1.0, trainable=True, dtype=tf.float64) \n",
    "        self.weights1 = tf.Variable(1.0, trainable=True, dtype=tf.float64)\n",
    "        self.weights2 = tf.Variable(1.0, trainable=True, dtype=tf.float64)\n",
    "    def loss_PDE(self, X_train_1,X_train_2,f11,f12,f21,f22):\n",
    "             loss_11=self.m11.u_t(X_train_1)+self.m11(X_train_1)*self.m11.u_x(X_train_1)+self.m12(X_train_1)*self.m12.u_x(X_train_1)\\\n",
    "        -2*self.m11.u_xx(X_train_1)+self.m1.u_x(X_train_1)-self.m12.u_xy(X_train_1)-f11\n",
    "             loss_11 = tf.reduce_mean(tf.square(loss_11))\n",
    "             loss_12=self.m12.u_t(X_train_1)+self.m11(X_train_1)*self.m11.u_y(X_train_1)+self.m12(X_train_1)*self.m12.u_y(X_train_1)\\\n",
    "        -2*self.m12.u_yy(X_train_1)+self.m1.u_y(X_train_1)-self.m11.u_xy(X_train_1)-self.m12.u_xx(X_train_1)-f12\n",
    "             loss_12= tf.reduce_mean(tf.square(loss_12))\n",
    "             loss_eq12=self.m11.u_x(X_train_1)+self.m12.u_y(X_train_1)\n",
    "             loss_eq12= tf.reduce_mean(tf.square(loss_eq12))\n",
    "             loss_21=self.m21.u_t(X_train_2)+self.m21(X_train_2)*self.m21.u_x(X_train_2)+self.m22(X_train_2)*self.m22.u_x(X_train_2)\\\n",
    "        -2*self.m21.u_xx(X_train_2)+self.m2.u_x(X_train_2)-self.m22.u_xy(X_train_2)-f21\n",
    "             loss_21 = tf.reduce_mean(tf.square(loss_21))\n",
    "             loss_22=self.m22.u_t(X_train_2)+self.m21(X_train_2)*self.m21.u_y(X_train_2)+self.m22(X_train_2)*self.m22.u_y(X_train_2)\\\n",
    "        -2*self.m22.u_yy(X_train_2)+self.m2.u_y(X_train_2)-self.m21.u_xy(X_train_2)-self.m22.u_xx(X_train_2)-f22\n",
    "             loss_22= tf.reduce_mean(tf.square(loss_22))\n",
    "             loss_eq22=self.m21.u_x(X_train_2)+self.m22.u_y(X_train_2)\n",
    "             loss_eq22= tf.reduce_mean(tf.square(loss_eq22))\n",
    "             loss_pde=loss_11+loss_12+loss_eq12+loss_21+loss_22+loss_eq22\n",
    "             return [loss_11,loss_12,loss_eq12,loss_21,loss_22,loss_eq22,loss_pde]\n",
    "    @tf.function\n",
    "    def loss_boundary(self, X_boundary_train_1,X_boundary_train_2):\n",
    "        loss_b11=self.m11(X_boundary_train_1)\n",
    "        loss_b11 = tf.reduce_mean(tf.square(loss_b11))\n",
    "        loss_b12=self.m12(X_boundary_train_1)\n",
    "        loss_b12 = tf.reduce_mean(tf.square(loss_b12))\n",
    "        loss_b21=self.m21(X_boundary_train_2)\n",
    "        loss_b21 = tf.reduce_mean(tf.square(loss_b21))\n",
    "        loss_b22=self.m22(X_boundary_train_2)\n",
    "        loss_b22 = tf.reduce_mean(tf.square(loss_b22))\n",
    "        loss_b=loss_b11+loss_b12+loss_b21+loss_b22\n",
    "        return [loss_b11,loss_b12,loss_b21,loss_b22,loss_b]\n",
    "    @tf.function\n",
    "    def loss_I(self, X_I_train):\n",
    "        loss_I11=self.m11(X_I_train)-self.m21(X_I_train)\n",
    "        loss_I11 = tf.reduce_mean(tf.square(loss_I11))\n",
    "        loss_I12=self.m12(X_I_train)-self.m22(X_I_train)\n",
    "        loss_I12 = tf.reduce_mean(tf.square(loss_I12))\n",
    "        loss_I21=2*self.m12.u_y(X_I_train)-self.m1(X_I_train)-2*self.m22.u_y(X_I_train)+self.m2(X_I_train)\n",
    "        loss_I21 = tf.reduce_mean(tf.square(loss_I21))\n",
    "        loss_I22=self.m22.u_x(X_I_train)+self.m21.u_y(X_I_train)-self.m12.u_x(X_I_train)-self.m11.u_y(X_I_train)\n",
    "        loss_I22 = tf.reduce_mean(tf.square(loss_I22))\n",
    "        loss_i=loss_I11+loss_I12+loss_I21+loss_I22\n",
    "        return  [loss_I11,loss_I12,loss_I21,loss_I22,loss_i]\n",
    "    @tf.function\n",
    "    def onetrainingstep(self, X_train_1, X_train_2, X_boundary_train_1, X_boundary_train_2, X_I_train, u_labels,f11,f12,f21,f22):\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            # 分别计算每个模型的误差\n",
    "            loss_pde=self.loss_PDE(X_train_1, X_train_2,f11,f12,f21,f22)\n",
    "            loss_b=self.loss_boundary(X_boundary_train_1, X_boundary_train_2)\n",
    "            loss_i=self.loss_I(X_I_train)\n",
    "            loss_t1 = self.m11.loss_u(X_train_1, u_labels[0])+self.m12.loss_u(X_train_1, u_labels[1])+self.m1.loss_u(X_train_1, u_labels[4])+loss_pde[0]+loss_pde[1]+loss_pde[2]\n",
    "            loss_t2 = self.m21.loss_u(X_train_2, u_labels[2])+self.m22.loss_u(X_train_2, u_labels[3])+self.m2.loss_u(X_train_2, u_labels[5])+loss_pde[3]+loss_pde[4]+loss_pde[5]\n",
    "            loss_b1 = loss_b[0]+loss_b[1]\n",
    "            loss_b2 = loss_b[2]+loss_b[3]\n",
    "            loss_i1 = loss_i[0]+loss_i[1]\n",
    "            loss_i2 = loss_i[2]+loss_i[3]\n",
    "            # 计算总误差\n",
    "            #loss_labels = self.m11.loss_u(X_train_1, u_labels[0]) + self.m12.loss_u(X_train_1, u_labels[1]) +self.m21.loss_u(X_train_2, u_labels[2])\\\n",
    "            #+self.m22.loss_u(X_train_2, u_labels[3])+ self.m1.loss_u(X_train_1, u_labels[4]) + self.m2.loss_u(X_train_2, u_labels[5])\n",
    "            #loss = loss_labels + self.loss_PDE(X_train_1, X_train_2,f11,f12,f21,f22)[-1] \\\n",
    "            #+ self.loss_boundary(X_boundary_train_1, X_boundary_train_2)[-1] + self.loss_I(X_I_train)[-1]\n",
    "            loss=loss_t1+loss_t2+loss_b1+loss_b2+loss_i1+loss_i2\n",
    "            a1= tf.math.sigmoid(2*self.weights11+0.5) * 2\n",
    "            a2= tf.math.sigmoid(2*self.weights12+0.5) * 2\n",
    "            a3= tf.math.sigmoid(2*self.weights21+0.5) * 2\n",
    "            a4= tf.math.sigmoid(2*self.weights22+0.5) * 2\n",
    "            a5= tf.math.sigmoid(2*self.weights1+0.5) * 2\n",
    "            a6= tf.math.sigmoid(2*self.weights2+0.5) * 2\n",
    "            #loss_alabels=a1*self.m11.loss_u(X_train_1, u_labels[0]) + a2*self.m12.loss_u(X_train_1, u_labels[1]) +a3*self.m21.loss_u(X_train_2, u_labels[2])\\\n",
    "            #+a4*self.m22.loss_u(X_train_2, u_labels[3])+ a5*self.m1.loss_u(X_train_1, u_labels[4]) + a6*self.m2.loss_u(X_train_2, u_labels[5])\n",
    "            loss_target=loss_t1*a1+loss_t2*a2+loss_b1*a3+loss_b2*a4+loss_i1*a5+loss_i2*a6\n",
    "            #loss_target=loss_alabels + self.loss_PDE(X_train_1, X_train_2,f11,f12,f21,f22)[-1] \\\n",
    "            #+ self.loss_boundary(X_boundary_train_1, X_boundary_train_2)[-1] + self.loss_I(X_I_train)[-1]\n",
    "            # 计算梯度\n",
    "            gradients_m11 =  tape.gradient(loss_target, self.m11.trainable_variables)\n",
    "            gradients_m12 =  tape.gradient(loss_target, self.m12.trainable_variables)\n",
    "            gradients_m21 =  tape.gradient(loss_target, self.m21.trainable_variables)\n",
    "            gradients_m22 =  tape.gradient(loss_target, self.m22.trainable_variables)\n",
    "            gradients_m1 =  tape.gradient(loss_target, self.m1.trainable_variables)\n",
    "            gradients_m2 =  tape.gradient(loss_target, self.m2.trainable_variables)\n",
    "            gradients_w11 =-tape.gradient(loss_target, self.weights11) \n",
    "            gradients_w12 = -tape.gradient(loss_target, self.weights12) \n",
    "            gradients_w21 = -tape.gradient(loss_target, self.weights21) \n",
    "            gradients_w22=-tape.gradient(loss_target, self.weights22) \n",
    "            gradients_w1= -tape.gradient(loss_target, self.weights1)\n",
    "            gradients_w2=-tape.gradient(loss_target, self.weights2)\n",
    "\n",
    "            # 应用梯度\n",
    "            self.optimizer.apply_gradients(zip(gradients_m11, self.m11.trainable_variables))\n",
    "            self.optimizer.apply_gradients(zip(gradients_m12, self.m12.trainable_variables))\n",
    "            self.optimizer.apply_gradients(zip(gradients_m21, self.m21.trainable_variables))\n",
    "            self.optimizer.apply_gradients(zip(gradients_m22, self.m22.trainable_variables))\n",
    "            self.optimizer.apply_gradients(zip(gradients_m1, self.m1.trainable_variables))\n",
    "            self.optimizer.apply_gradients(zip(gradients_m2, self.m2.trainable_variables))\n",
    "            self.current_optimizer.apply_gradients(zip([gradients_w11,gradients_w12, gradients_w21,gradients_w22,gradients_w1,gradients_w2],[self.weights11,self.weights12,self.weights21,self.weights22,self.weights1,self.weights2]))\n",
    "            \n",
    "        del tape\n",
    "        return loss\n",
    "    def train(self,X_train_1,X_train_2,X_boundary_train_1,X_boundary_train_2,X_I_train,u_labels,f11,f12,f21,f22,epochs=300):\n",
    "         # 预热模型\n",
    "        self.set_optimizer(1)\n",
    "        self.onetrainingstep(X_train_1,X_train_2,X_boundary_train_1,X_boundary_train_2,X_I_train,u_labels,f11,f12,f21,f22)\n",
    "        start_time = time.time()\n",
    "        for epoch in tf.range(2, epochs + 1):\n",
    "            self.set_optimizer(epoch)\n",
    "            loss=self.onetrainingstep(X_train_1, X_train_2, X_boundary_train_1, X_boundary_train_2, X_I_train, u_labels,f11,f12,f21,f22)\n",
    "            #if epoch % 20 == 0:\n",
    "                #self.update_weights(loss_m11, loss_m12, loss_m21, loss_m22, loss_m1, loss_m2) \n",
    "            if epoch % 50 == 0:\n",
    "                end_time = time.time()\n",
    "                elapsed_time = end_time - start_time\n",
    "                tf.print(\"Epoch\", epoch, \"loss:\", loss, \"Elapsed time:\", elapsed_time, \"seconds\")\n",
    "                start_time = time.time()  \n",
    "    def predict(self, X_pre_1,X_pre_2,true_labels):\n",
    "        u11_pred = self.m11(X_pre_1)\n",
    "        u12_pred = self.m12(X_pre_1)\n",
    "        p1_pred = self.m1(X_pre_1)\n",
    "        u21_pred = self.m21(X_pre_2)\n",
    "        u22_pred = self.m22(X_pre_2)\n",
    "        p2_pred = self.m2(X_pre_2)\n",
    "        u11_error = u11_pred - true_labels[0]\n",
    "        u12_error = u12_pred - true_labels[1]\n",
    "        u21_error = u21_pred - true_labels[2]\n",
    "        u22_error = u22_pred - true_labels[3]\n",
    "        p1_error = p1_pred - true_labels[4]\n",
    "        p2_error = p2_pred - true_labels[5]\n",
    "        mse_u11 = tf.reduce_mean(tf.square(u11_error))\n",
    "        mse_u12 = tf.reduce_mean(tf.square(u12_error))\n",
    "        mse_p1 = tf.reduce_mean(tf.square(p1_error))\n",
    "        mse_u21 = tf.reduce_mean(tf.square(u21_error))\n",
    "        mse_u22 = tf.reduce_mean(tf.square(u22_error))\n",
    "        mse_p2 = tf.reduce_mean(tf.square(p2_error))\n",
    "        return  (u11_pred, u12_pred, p1_pred, u21_pred, u22_pred, p2_pred), (u11_error, u12_error, p1_error, u21_error, u22_error, p2_error), (mse_u11, mse_u12, mse_p1, mse_u21, mse_u22, mse_p2)\n",
    "layers = [3, 40,40,40,1]  \n",
    "u11pinn = OnePinn(layers)\n",
    "u12pinn = OnePinn(layers)\n",
    "p1pinn = OnePinn(layers)\n",
    "u21pinn = OnePinn(layers)\n",
    "u22pinn = OnePinn(layers)\n",
    "p2pinn = OnePinn(layers)\n",
    "finpinn=UltPinn(u11pinn,u12pinn,u21pinn,u22pinn,p1pinn,p2pinn)\n",
    "def generate_data(num):\n",
    "    num_points = num\n",
    "    num_jiedian = int(num/3)\n",
    "    num_zhongdian=num-num_jiedian\n",
    "    x_min, x_max = 0, 1\n",
    "    y_1_min, y_1_max = 0, 1\n",
    "    t_min, t_max = 0, 1\n",
    "    y_2_min, y_2_max = -1,0\n",
    "\n",
    "    x_train = np.random.uniform(x_min, x_max, (num_points, 1))\n",
    "    y_1_train = np.random.uniform(y_1_min, y_1_max, (num_points, 1))\n",
    "    y_2_train = np.random.uniform(y_2_min, y_2_max, (num_points, 1))\n",
    "    t_train = np.random.uniform(t_min, t_max, (num_points, 1))\n",
    "    x_train = tf.convert_to_tensor(x_train, dtype=tf.float64)\n",
    "    y_1_train= tf.convert_to_tensor(y_1_train, dtype=tf.float64)\n",
    "    y_2_train = tf.convert_to_tensor(y_2_train, dtype=tf.float64)\n",
    "    t_train  = tf.convert_to_tensor(t_train , dtype=tf.float64)\n",
    "\n",
    "    u11_train = u11(x_train, y_1_train, t_train)\n",
    "    u12_train = u12(x_train, y_1_train, t_train)\n",
    "    p1_train = p1(x_train, y_1_train, t_train)\n",
    "    u21_train = u21(x_train, y_2_train, t_train)\n",
    "    u22_train = u22(x_train, y_2_train, t_train)\n",
    "    p2_train = p2(x_train, y_2_train, t_train)\n",
    "    x_, y_1, t_ = x_train, y_1_train, t_train\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        tape.watch([x_,y_1,t_])\n",
    "        u_11=u11(x_,y_1,t_)\n",
    "        u_12=u12(x_,y_1,t_)\n",
    "        p_1=p1(x_,y_1,t_)\n",
    "        u11x=tape.gradient( u_11, x_)\n",
    "        u11y=tape.gradient(u_11, y_1)\n",
    "        u11t=tape.gradient(u_11, t_)\n",
    "        u12x=tape.gradient(u_12, x_)\n",
    "        u12y=tape.gradient(u_12, y_1)\n",
    "        u12t=tape.gradient(u_12, t_)\n",
    "        p1x=tape.gradient( p_1, x_)\n",
    "        p1y=tape.gradient( p_1, y_1)\n",
    "    u11xx=tape.gradient(u11x,x_)\n",
    "    u11xy=tape.gradient(u11x,y_1)\n",
    "    u12xx=tape.gradient(u12x, x_)\n",
    "    u12xy=tape.gradient(u12x, y_1)\n",
    "    u12yy=tape.gradient(u12y, y_1)\n",
    "    u11yy=tape.gradient(u11y, y_1)\n",
    "    del tape\n",
    "    f11=u11t+u_11*u11x+u_12*u12x-2*u11xx+p1x-u12xy\n",
    "    f12=u12t+u_11*u11y+u_12*u12y-u12xx-u11xy-2*u12yy+p1y\n",
    "    x_, y_2, t_ = x_train, y_2_train, t_train\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        tape.watch([x_,y_2,t_])\n",
    "        u_21=u21(x_,y_2,t_)\n",
    "        u_22=u22(x_,y_2,t_)\n",
    "        p_2=p2(x_,y_2,t_)\n",
    "        u21x=tape.gradient(u_21, x_)\n",
    "        u21y=tape.gradient(u_21, y_2)\n",
    "        u21t=tape.gradient(u_21, t_)\n",
    "        u22x=tape.gradient(u_22, x_)\n",
    "        u22y=tape.gradient(u_22, y_2)\n",
    "        u22t=tape.gradient(u_22, t_)\n",
    "        p2x=tape.gradient( p_2, x_)\n",
    "        p2y=tape.gradient( p_2, y_2)\n",
    "    u21xx=tape.gradient(u21x,x_)\n",
    "    u21xy=tape.gradient(u21x,y_2)\n",
    "    u22xx=tape.gradient(u22x, x_)\n",
    "    u22xy=tape.gradient(u22x, y_2)\n",
    "    u22yy=tape.gradient(u22y, y_2)\n",
    "    u21yy=tape.gradient(u21y, y_2)\n",
    "    del tape\n",
    "    \n",
    "    f21=u21t+u_21*u21x+u_22*u22x-2*u21xx+p2x-u22xy\n",
    "    f22=u22t+u_21*u21y+u_22*u22y-u22xx-u21xy-2*u22yy+p2y\n",
    "    \n",
    "    X_train_1 = np.concatenate([x_train, y_1_train, t_train], axis=1)\n",
    "    X_train_2 = np.concatenate([x_train, y_2_train, t_train], axis=1)\n",
    "    X_boundary_train_1_1=np.concatenate([np.zeros_like(x_train[0:num_jiedian,:]), y_1_train[0:num_jiedian,:], t_train[0:num_jiedian,:]],axis=1)\n",
    "    X_boundary_train_1_2=np.concatenate([x_train[num_jiedian:num_zhongdian,:], np.ones_like(y_1_train[num_jiedian:num_zhongdian,:]), t_train[num_jiedian:num_zhongdian,:]],axis=1)\n",
    "    X_boundary_train_1_3=np.concatenate([np.ones_like(x_train[num_zhongdian:num_points,:]), y_1_train[num_zhongdian:num_points,:], t_train[num_zhongdian:num_points,:]],axis=1)\n",
    "    X_boundary_train_1=np.concatenate([X_boundary_train_1_1, X_boundary_train_1_2, X_boundary_train_1_3], axis=0)\n",
    "    X_boundary_train_2_1=np.concatenate([np.zeros_like(x_train[0:num_jiedian,:]), y_2_train[0:num_jiedian,:], t_train[0:num_jiedian,:]],axis=1)\n",
    "    X_boundary_train_2_2=np.concatenate([x_train[num_jiedian:num_zhongdian,:], np.ones_like(y_2_train[num_jiedian:num_zhongdian,:]), t_train[num_jiedian:num_zhongdian,:]],axis=1)\n",
    "    X_boundary_train_2_3=np.concatenate([np.ones_like(x_train[num_zhongdian:num_points,:]), y_2_train[num_zhongdian:num_points,:], t_train[num_zhongdian:num_points,:]],axis=1)\n",
    "    X_boundary_train_2=np.concatenate([X_boundary_train_2_1, X_boundary_train_2_2, X_boundary_train_2_3], axis=0)\n",
    "    X_I_train=np.concatenate([x_train,np.zeros_like(y_1_train), t_train], axis=1)\n",
    "\n",
    "    u_labels = [u11_train, u12_train, u21_train, u22_train, p1_train, p2_train]\n",
    "    return X_train_1,X_train_2,X_boundary_train_1,X_boundary_train_2,X_I_train,u_labels,f11,f12,f21,f22\n",
    "X_train_1,X_train_2,X_boundary_train_1,X_boundary_train_2,X_I_train,u_labels,f11,f12,f21,f22= generate_data(900)\n",
    "X_pre_1,X_pre_2,X_boundary_pre_1,X_boundary_pre_2,X_I_pre,u_pre_labels,f11_pre,f12_pre,f21_pre,f22_pre= generate_data(9000)\n",
    "model=finpinn\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001))\n",
    "model.train(X_train_1,X_train_2,X_boundary_train_1,X_boundary_train_2,X_I_train,u_labels,f11,f12,f21,f22,epochs=500)\n",
    "predictions, errors, mse = model.predict(X_pre_1,X_pre_2, u_pre_labels)\n",
    "print(\"MSE for u11:\", mse[0])\n",
    "print(\"MSE for u12:\", mse[1])\n",
    "print(\"MSE for p1:\", mse[2])\n",
    "print(\"MSE for u21:\", mse[3])\n",
    "print(\"MSE for u22:\", mse[4])\n",
    "print(\"MSE for p2:\", mse[5])\n",
    "u11_pred, u12_pred, p1_pred, u21_pred, u22_pred, p2_pred = predictions\n",
    "un11=u11_pred.numpy().reshape(X_pre_1.shape[0])\n",
    "un12=u12_pred.numpy().reshape(X_pre_1.shape[0])\n",
    "un21=u21_pred.numpy().reshape(X_pre_1.shape[0])\n",
    "un22=u22_pred.numpy().reshape(X_pre_1.shape[0])\n",
    "pn1=p1_pred.numpy().reshape(X_pre_1.shape[0])\n",
    "pn2=p2_pred.numpy().reshape(X_pre_1.shape[0])\n",
    "file_path =\"D:\\Desktop\\graduate paper\\ spaw fluid pinns data_pred.npz\"\n",
    "predictions = {\n",
    "    \"u11_pred\": un11,\n",
    "    \"u12_pred\": un12,\n",
    "    \"p1_pred\": pn1,\n",
    "    \"u21_pred\": un21,\n",
    "    \"u22_pred\": un22,\n",
    "    \"p2_pred\": pn2,\n",
    "    \"x_pred_1\":X_pre_1,\n",
    "    \"x_pred_2\":X_pre_2\n",
    "}\n",
    "\n",
    "#np.savez(file_path, **predictions)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8384fd30-e32d-44f1-bece-e13fcf7bc668",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
